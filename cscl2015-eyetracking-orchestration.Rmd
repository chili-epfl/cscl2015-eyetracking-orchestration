---
title: "The Burden of Facilitating Collaboration: Towards Estimation of Teacher Orchestration Load using Eye-tracking Measures"
author: "Luis P. Prieto, Kshitij Sharma, Yun Wen & Pierre Dillenbourg"
output: html_document
---

This is an R Markdown document to reproduce the main data preprocessing, analysis and visualization for the homonymous [CSCL2015 conference](http://isls.org/cscl2015/) paper. Below, we reproduce the abstract of the paper, a summary of the context and methods of the studies, and then the analysis and visualization of the studies themselves.

## Abstract

Teacher facilitation of CSCL activities is widely recognized as one of the main factors affecting student learning outcomes in formal face-to-face settings. However, the orchestration load that such facilitation represents for the teacher, within the constraints of an authentic classroom, remains under-researched. This paper presents a novel method to estimate the cognitive load of teachers during facilitation of CSCL sessions, using mobile eye-tracking techniques. Throughout **three studies of increasing authenticity**, we demonstrate the feasibility of this approach, and extract insights about classroom usability challenges in CSCL practice: the increased load of class-level facilitation, or the real-time monitoring of students’ progress. This new instrument in the CSCL researcher’s toolkit can help focus our attention in critical, fine-grained classroom usability episodes, to make more informed design decisions.

## The studies: Context and Methods

Our main research question is: can we use eye-tracking techniques to follow cognitive load of teachers facilitating CSCL in authentic settings? In order to explore this question, we set out to apply the measurement of the four metrics used by [Buettner (2013)](http://link.springer.com/chapter/10.1007/978-3-642-40942-4_4) in three studies (with increasing degree of authenticity).

Study | 1 - Analytical | 2 - Semi-authentic | 3 - Authentic
------|------------|----------------|----------
Setting | Laboratory | Multi-tabletop classroom, lab ‘open doors’ day | Authentic course, classroom including projector and laptops
Goal | Test method in different task, see evolution of CL over time | Feasibility of eye-tracking within classroom constraints, insights about multi-tabletop classroom usability | Feasibility of eye-tracking in real course, individual differences of novice/expert teachers
Subjects | 16 participants | 1 facilitator-researcher, 61 primary school students | 1 expert teacher, 1 novice teacher, 12-14 students
Task | Game-based | Facilitation of small group collaborative work | Mix of lecture and collaborative work
Study duration | 128 games in total, 1.5-4 minutes each | 3 sessions, 35-45 min each | 3 sessions (2 expert, 1 novice), 45-65 min each
Analysis | Calculation of Load Index, comparison with Tetris game metrics | Calculation of Load Index, Video coding, Comparison of high- and low-load orchestration profiles | Calculation of Load Index, Video coding, Comparison of high- and low-load orchestration profiles

The data analysis of the three studies relies mainly on the calculation of what we call a **Load Index** inferred from eye-tracking measures of the subject. The four measures used by Buettner (mean pupil diameter, pupil diameter standard deviation, saccade speed and number of fixations longer than 500ms) were calculated over a sliding window of 10 seconds (with a 5s slide from one window to the next). Then, a median cut was performed (using the median value of that measurement for the session). Finally, the Load Index was calculated by counting the number of measures that were above the game median for that 10-second window (thus going from 0 to 4), as an estimation of how likely it is that a certain 10-second window represented higher cognitive load than other windows in that session.

In the second and third studies, the episodes (10-second windows) of extreme Load Index (0 and 4) were manually **video coded**, to describe different aspects of that episode, with regard to the orchestration taking place in that moment:

Orchestration dimension | Teacher activity | Social plane | Main gaze focus
------------------------|------------------|--------------|----------------
Example codes | Explanation/Lecturing (EXP), Monitoring (MON), Task distribution or transition (TDT), Technical or conceptual repairs (REP)... | Individual (IND), Small group (GRP), Class-wide (CLS) | Students’ faces (FAC) or backs (BAK), Tabletop surface (TAB), Paper worksheet (PAP)...

Then, the high- and low- Load Index episodes are compared along these three dimensions, to see if they are significantly different (with a Pearson's chi-squared test of independence).

## Before starting: Data download

First of all, we download the datasets for the three studies, which have been published in Zenodo: 

* [Dataset for Study 1 (Tetris games) MISSING LINK]()
* [Dataset for Study 2 (Multi-tabletop sessions in the lab, primary school students) MISSING LINK]()
* [Dataset for Study 3 (Laptop-and-projector sessions in a university course) MISSING LINK]()

```{r}
# We load the useful scripts and packages needed throughout the report
source("./lib/rollingWindows.R")
source("./lib/loadIndex.R")

rootdir <- getwd()
# If not present already, download dataset study 1 and uncompress it to Study1/
setwd(paste(rootdir,"/data/Study1",sep=""))
# if(!file.exists())...
# unzip/bz2...
# If not present already, download dataset study 2 and uncompress it to Study2/
# If not present already, download dataset study 3 and uncompress it to Study3/
```

## Study 1 (Analytical study): cognitive load in a simple game-based task 

As a first step in our exploration of eye-tracking to follow teacher cognitive load, and taking into account that eye responses are often task-dependent, we devised a first test for the validity of the measurements proposed by Buettner. Using existing eye-tracking data from a previous experiment in which participants played a computer game (unrelated to the task in Buettner’s study), we estimated the evolution of the CL of participants throughout their experience, to see whether the results were consistent with what we knew about the game task in question and its temporal evolution.

### Data pre-processing

We uncompress the data from the study (warning, it is almost 5G of files!). This includes mainly a time series of eyetracking data along with the value of several game variables (e.g., mean Tetris stack height) in each instant, plus an additional set of files with the fixation details of each game in the experiment. 

Once we uncompress the data, we run the pre-processing of data: basically, separating the data for each game, and calculating the four eyetracking variables of interest, over 10-second rolling windows with 5-second slide:

* Pupil diameter mean
* Pupil diameter standard deviation
* Number of fixations with duration >500ms
* Average saccade speed

(see ```./data/Study1/preprocessStudy1Data.R``` and ```./lib/rollingWindows.R``` files for details)

```{r, cache=TRUE}
setwd(paste(rootdir,"/data/Study1",sep=""))
source("preprocessStudy1Data.R")
# We do the preprocessing, which will generate a Rda file with the 10s
# window data, and will return the name of the file
cleandatafile <- "Study1ProcessedData.Rda"
if(!file.exists(cleandatafile)){
    if(!file.exists("ALLCombinedVariables_timeseriesPupilEvolution.csv")){
        unzip("ALLCombinedVariables_timeseriesPupilEvolution.csv.zip")                
    }
    unzip("FixationDetails.zip")
    preprocessStudy1()
}
```

### Data analysis

The main basic data analysis we do here is just to calculate the Load Index for each 10s window in a game (see ```./lib/loadIndex.R``` file for details):

```{r}
# We load the overall dataset with the data from the 10s sliding windows
totaldata <- get(load(paste(rootdir,"/data/Study1/",cleandatafile,sep="")))

# This dataframe will contain the data with the added Load Index data
loaddata <- data.frame()

# We calculate the load index, considering each game a different session
# for the effects of the median cut
games = unique(totaldata$gameID[])
for(game in games){
    data <- totaldata[totaldata$gameID == game,]
    # We add the columns with Load Index data
    newdata <- calculateLoadIndexSession(data)    
    # We join the new data into a dataset with all session's data
    if(length(loaddata)==0) loaddata <- newdata
    else loaddata <- rbind(loaddata,newdata)
}       

# Now, loaddata will contain the data to be summarized/visualized
```


### Main Results and visualization

If we look at the mean values of Load index and different game variables (mainly, the Tetris mean stack height and its variance)

**1. Temporal evolution**

```{r, message=FALSE, warning=FALSE}
require("gplots")
require("ggplot2")

# TODO: What was the code for this graph - Figure 1a in the paper??

```

We can see the average cognitive load index (brown curve) of participants as time went on, as well as the temporal evolution of the stack height (green curve) and stack variance (blue curve). If we think in terms of the particular task (the Tetris game), we get interesting insights into how the cognitive load evolves over time: at the beginning (low mean stack heights) the cognitive load is high (as many alternative options for placing a new piece are open to decide amongst), and it generally goes down as the game goes towards the end (higher mean stack height), until we eventually disengage from the game when we give up. Similar but opposite is the effect of stack variance (higher variance implies more complex stack profiles, difficult to process and with more open alternatives of placement).

**2. Load Index vs. Game variables (stack height mean/variance)**

```{r, message=FALSE, warning=FALSE}
plotmeans(loaddata$value.stackMean~loaddata$Load, 
          xlab="Load Index",
            ylab="Mean stack height (avg. 10s episode)",
            main="Load Index vs. Stack height", barwidth=2)
plotmeans(loaddata$value.stackVar~loaddata$Load,
          xlab="Load Index",
            ylab="Stack height variance (avg. 10s episode)",
            main="Load Index vs. Stack height", barwidth=2)
```

The main descriptive statistics of both game variables on 10-second windows, classified by their load index. Our results show that the Load Index is positively correlated with stack variance, and negatively correlated with the mean stack height, and that such an effect is more clearly apparent in the extreme values of the load index.

### Summary of results

These results show that the Load Index, computed as described above, has potential for distinguishing different kinds of episodes occurring during the task (represented by moments with different mean stack heights and variances). We also see how CL may be related with the amount of open alternatives in each moment (in a sense, the uncertainty or the ‘entropy’ we perceive about the current game situation).

## Study 2 (Semi-authentic study): multi-tabletops at an open-doors day in the lab


## Study 3 (Authentic study): master-level university course



## Conclusions

```{r}
summary(cars)
```

You can also embed plots, for example:

```{r, echo=FALSE}
plot(cars)
```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
